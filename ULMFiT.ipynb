{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 20 06:50:20 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-FHHL...  On   | 00000000:B1:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    25W / 150W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting fastai\n",
      "\u001b[?25l  Downloading http://mirrors.aliyun.com/pypi/packages/8a/3b/84d71cc369158120bac220eb4d60426b8e2c06cdebfd6a3918844400fd08/fastai-2.5.1-py3-none-any.whl (188kB)\n",
      "\u001b[K     |████████████████████████████████| 194kB 4.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fastdownload<2,>=0.0.5\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/4a/7d/d352ae8f0aa2170f9e0ae4676148675a738cf9fd0c034bd024b82f7df8ed/fastdownload-0.0.5-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: spacy<4 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from fastai) (2.2.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from fastai) (0.22.1)\n",
      "Collecting fastcore<1.4,>=1.3.8\n",
      "\u001b[?25l  Downloading http://mirrors.aliyun.com/pypi/packages/17/58/6c3d0426a58677eddaec505587d6ef68f4338668e962eedd8cc1372b62f2/fastcore-1.3.26-py3-none-any.whl (56kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 26.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pip in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from fastai) (19.3.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from fastai) (3.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from fastai) (0.25.3)\n",
      "Collecting torch<1.10,>=1.7.0\n",
      "\u001b[?25l  Downloading http://mirrors.aliyun.com/pypi/packages/d2/a9/b3cea4a97ffabd6639e71608814dbd08081e202e8ac9580250273c0541ff/torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4MB)\n",
      "\u001b[K     |████████████████████████████████| 831.4MB 12.1MB/s eta 0:00:01    |███▌                            | 92.1MB 13.8MB/s eta 0:00:54     |█████▋                          | 146.3MB 9.2MB/s eta 0:01:15     |█████▉                          | 151.2MB 16.4MB/s eta 0:00:42     |██████                          | 153.1MB 16.4MB/s eta 0:00:42     |██████▉                         | 178.0MB 9.9MB/s eta 0:01:07     |███████                         | 179.1MB 9.9MB/s eta 0:01:07     |███████▏                        | 186.3MB 12.3MB/s eta 0:00:53     |███████▋                        | 199.0MB 13.6MB/s eta 0:00:47     |███████▊                        | 201.4MB 13.6MB/s eta 0:00:47     |███████████▍                    | 294.6MB 8.2MB/s eta 0:01:06     |████████████▍                   | 322.0MB 8.4MB/s eta 0:01:01     |████████████▍                   | 322.7MB 8.4MB/s eta 0:01:01     |████████████▋                   | 327.9MB 8.4MB/s eta 0:01:01     |████████████▊                   | 329.1MB 8.4MB/s eta 0:01:01     |█████████████▉                  | 360.7MB 13.0MB/s eta 0:00:37     |██████████████▏                 | 368.6MB 13.0MB/s eta 0:00:36     |██████████████▎                 | 372.2MB 15.4MB/s eta 0:00:30     |██████████████▍                 | 372.8MB 15.4MB/s eta 0:00:30     |███████████████▏                | 394.4MB 12.2MB/s eta 0:00:36     |███████████████▌                | 403.4MB 12.2MB/s eta 0:00:36     |████████████████▌               | 427.5MB 26.0MB/s eta 0:00:16     |████████████████▌               | 428.1MB 26.0MB/s eta 0:00:16     |████████████████▋               | 431.4MB 11.1MB/s eta 0:00:37     |████████████████▉               | 437.1MB 11.1MB/s eta 0:00:36     |█████████████████▏              | 444.7MB 11.5MB/s eta 0:00:34     |█████████████████▉              | 462.5MB 13.0MB/s eta 0:00:29     |█████████████████▉              | 463.8MB 13.0MB/s eta 0:00:29     |██████████████████▊             | 486.7MB 6.2MB/s eta 0:00:56     |███████████████████             | 492.8MB 8.0MB/s eta 0:00:43     |███████████████████▏            | 499.2MB 8.0MB/s eta 0:00:42     |████████████████████▌           | 531.5MB 14.6MB/s eta 0:00:21     |█████████████████████           | 547.4MB 6.6MB/s eta 0:00:44     |██████████████████████▏         | 575.9MB 8.9MB/s eta 0:00:29     |███████████████████████         | 595.5MB 13.1MB/s eta 0:00:18     |███████████████████████▎        | 603.7MB 9.7MB/s eta 0:00:24     |███████████████████████▌        | 610.7MB 9.7MB/s eta 0:00:23     |████████████████████████        | 622.6MB 8.2MB/s eta 0:00:26     |████████████████████████▍       | 632.9MB 12.6MB/s eta 0:00:16     |██████████████████████████▎     | 682.1MB 10.9MB/s eta 0:00:14     |███████████████████████████     | 704.2MB 13.7MB/s eta 0:00:10     |███████████████████████████▍    | 712.6MB 13.7MB/s eta 0:00:09     |███████████████████████████▌    | 714.9MB 7.3MB/s eta 0:00:16     |███████████████████████████▋    | 716.1MB 7.3MB/s eta 0:00:16     |███████████████████████████▉    | 722.1MB 7.3MB/s eta 0:00:15     |███████████████████████████▉    | 724.0MB 7.3MB/s eta 0:00:15     |████████████████████████████    | 728.3MB 10.9MB/s eta 0:00:10     |████████████████████████████▎   | 736.0MB 10.9MB/s eta 0:00:09     |████████████████████████████▍   | 737.9MB 10.9MB/s eta 0:00:09     |█████████████████████████████   | 752.6MB 12.2MB/s eta 0:00:07     |█████████████████████████████   | 755.8MB 12.2MB/s eta 0:00:07     |█████████████████████████████▍  | 764.0MB 13.6MB/s eta 0:00:05     |███████████████████████████████▌| 818.5MB 13.2MB/s eta 0:00:01     |███████████████████████████████▋| 821.6MB 13.2MB/s eta 0:00:01     |███████████████████████████████▊| 824.8MB 12.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from fastai) (2.22.0)\n",
      "Collecting torchvision>=0.8.2\n",
      "\u001b[?25l  Downloading http://mirrors.aliyun.com/pypi/packages/71/25/31f5d3c62b80aff0d95b9306e09487a29531a2a3d05cf767376bdc087c3a/torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1MB)\n",
      "\u001b[K     |████████████████████████████████| 22.1MB 13.8MB/s eta 0:00:01    |██▎                             | 1.6MB 15.5MB/s eta 0:00:02     |████████████████████████████▌   | 19.7MB 13.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from fastai) (20.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from fastai) (1.4.1)\n",
      "Collecting fastprogress>=0.2.4\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/eb/1f/c61b92d806fbd06ad75d08440efe7f2bd1006ba0b15d086debed49d93cdc/fastprogress-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from fastai) (6.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from fastai) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: thinc<7.4.0,>=7.3.0 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from spacy<4->fastai) (7.3.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from spacy<4->fastai) (45.2.0)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from spacy<4->fastai) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from spacy<4->fastai) (2.0.3)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from spacy<4->fastai) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from spacy<4->fastai) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from spacy<4->fastai) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from spacy<4->fastai) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from spacy<4->fastai) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.1.0 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from spacy<4->fastai) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from spacy<4->fastai) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from scikit-learn->fastai) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from matplotlib->fastai) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from matplotlib->fastai) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from matplotlib->fastai) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from pandas->fastai) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from torch<1.10,>=1.7.0->fastai) (3.7.4.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from requests->fastai) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from requests->fastai) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from requests->fastai) (1.25.7)\n",
      "Requirement already satisfied, skipping upgrade: six in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from packaging->fastai) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy<4->fastai) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /root/miniconda3/envs/myconda/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (8.0.2)\n",
      "Installing collected packages: fastcore, fastprogress, fastdownload, torch, torchvision, fastai\n",
      "  Found existing installation: fastprogress 0.2.2\n",
      "    Uninstalling fastprogress-0.2.2:\n",
      "      Successfully uninstalled fastprogress-0.2.2\n",
      "  Found existing installation: torch 1.3.1\n",
      "    Uninstalling torch-1.3.1:\n",
      "      Successfully uninstalled torch-1.3.1\n",
      "  Found existing installation: torchvision 0.4.2\n",
      "    Uninstalling torchvision-0.4.2:\n",
      "      Successfully uninstalled torchvision-0.4.2\n",
      "  Found existing installation: fastai 1.0.60\n",
      "    Uninstalling fastai-1.0.60:\n",
      "      Successfully uninstalled fastai-1.0.60\n",
      "Successfully installed fastai-2.5.1 fastcore-1.3.26 fastdownload-0.0.5 fastprogress-1.0.0 torch-1.9.0 torchvision-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='144441344' class='' max='144440600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [144441344/144440600 00:24<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fine-tune a language model on IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_lm = TextDataLoaders.from_folder(path, is_lm=True, valid_pct=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos i do n't see the sense in going through so much trouble to make a movie like this , and then throw the history book out the window . xxmaj there was n't a single accurate detail in that movie other than the fact than xxmaj richtofen died , which i was grateful for at the end so i did n't have to watch any more . xxmaj movies like this</td>\n",
       "      <td>i do n't see the sense in going through so much trouble to make a movie like this , and then throw the history book out the window . xxmaj there was n't a single accurate detail in that movie other than the fact than xxmaj richtofen died , which i was grateful for at the end so i did n't have to watch any more . xxmaj movies like this are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxmaj nikolaidis has the actors address the camera at various intervals . xxmaj the stand - out performance is that of the insane daughter , played by the extraordinary and outlandishly sexy xxmaj michele xxmaj valley . xxmaj panos xxmaj thanassoulis , as xxmaj sling , has virtually no dialog , but makes his mark in a pivotal but surprisingly neutral role . xxmaj black and white cinematography by xxmaj xxunk xxmaj</td>\n",
       "      <td>nikolaidis has the actors address the camera at various intervals . xxmaj the stand - out performance is that of the insane daughter , played by the extraordinary and outlandishly sexy xxmaj michele xxmaj valley . xxmaj panos xxmaj thanassoulis , as xxmaj sling , has virtually no dialog , but makes his mark in a pivotal but surprisingly neutral role . xxmaj black and white cinematography by xxmaj xxunk xxmaj xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>his girlfriend and dumping her body on the train . xxmaj mike , a loud little kid ( dale xxmaj belding ) , witnesses him . xxmaj harold tries to kill him , but is distracted and xxmaj mike runs away . \\n\\n xxmaj later , xxmaj harold ends up in a hotel / boarding house ( ? ) in a small town where he runs into xxmaj jean xxmaj maxwell (</td>\n",
       "      <td>girlfriend and dumping her body on the train . xxmaj mike , a loud little kid ( dale xxmaj belding ) , witnesses him . xxmaj harold tries to kill him , but is distracted and xxmaj mike runs away . \\n\\n xxmaj later , xxmaj harold ends up in a hotel / boarding house ( ? ) in a small town where he runs into xxmaj jean xxmaj maxwell ( the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>playing with them . \" uncle \" finally gets a retrieve , when he develops a notion of parenting . xxmaj this calls attention , perhaps , to the \" dirty little secret \" not being confronted in our society about autism - that it really has a lot to do with neglecting children . xxmaj the details of xxmaj tian - bai 's upbringing that lead to his murderous behavior are</td>\n",
       "      <td>with them . \" uncle \" finally gets a retrieve , when he develops a notion of parenting . xxmaj this calls attention , perhaps , to the \" dirty little secret \" not being confronted in our society about autism - that it really has a lot to do with neglecting children . xxmaj the details of xxmaj tian - bai 's upbringing that lead to his murderous behavior are almost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that boob from a gas station grease pit does not work at all - it just ruins the movie . i think in retrospect it 's not the whole movie i hate so much as the fact that ' the boob ' is so obviously not someone who would be on a space ship - not even to ' grease the hatch . ' xxup omg . i wonder if he checked</td>\n",
       "      <td>boob from a gas station grease pit does not work at all - it just ruins the movie . i think in retrospect it 's not the whole movie i hate so much as the fact that ' the boob ' is so obviously not someone who would be on a space ship - not even to ' grease the hatch . ' xxup omg . i wonder if he checked the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_lm.show_batch(max_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [105070592/105067061 00:15<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(dls_lm, AWD_LSTM, metrics=[accuracy, Perplexity()], path=path, wd=0.1).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.425848</td>\n",
       "      <td>4.118347</td>\n",
       "      <td>0.285327</td>\n",
       "      <td>61.457550</td>\n",
       "      <td>16:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('1epoch')\n",
    "learn = learn.load('1epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.074031</td>\n",
       "      <td>3.915394</td>\n",
       "      <td>0.304144</td>\n",
       "      <td>50.168850</td>\n",
       "      <td>17:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.014558</td>\n",
       "      <td>3.869981</td>\n",
       "      <td>0.308912</td>\n",
       "      <td>47.941479</td>\n",
       "      <td>17:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.966302</td>\n",
       "      <td>3.811498</td>\n",
       "      <td>0.315168</td>\n",
       "      <td>45.218143</td>\n",
       "      <td>17:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.918932</td>\n",
       "      <td>3.762368</td>\n",
       "      <td>0.320792</td>\n",
       "      <td>43.050266</td>\n",
       "      <td>17:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.859914</td>\n",
       "      <td>3.746400</td>\n",
       "      <td>0.322813</td>\n",
       "      <td>42.368267</td>\n",
       "      <td>17:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fine-tune a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_clas = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', text_vocab=dls_lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load_encoder('finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.242223</td>\n",
       "      <td>0.191658</td>\n",
       "      <td>0.924960</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.218153</td>\n",
       "      <td>0.172692</td>\n",
       "      <td>0.933640</td>\n",
       "      <td>02:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.189482</td>\n",
       "      <td>0.159275</td>\n",
       "      <td>0.940680</td>\n",
       "      <td>03:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.174046</td>\n",
       "      <td>0.154317</td>\n",
       "      <td>0.942520</td>\n",
       "      <td>04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.134750</td>\n",
       "      <td>0.151739</td>\n",
       "      <td>0.943800</td>\n",
       "      <td>04:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
